{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring and Visualizing Beyond the East Busway Data\n",
    "## Matthew Samach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import numpy as np\n",
    "import warnings\n",
    "import itertools\n",
    "import helpers as hp\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Data Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"../Data/responses_anonymous.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data are not in First Normal Form (there are multiple values per cell in some cases). Will have to write a function to move data into that form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Writing a function to get this type of data into Sankey format. Will then write a wrapper to graph the Sankey\n",
    "import helpers as hp\n",
    "\n",
    "def sankeyFormat(dFrame, col_indeces):\n",
    "    \n",
    "    if len(col_indeces) != 2:\n",
    "        print(\"Column indeces should only have 2 items\")\n",
    "        return \n",
    "\n",
    "    dFrame = hp.firstNormal(dFrame = raw_data, col_indeces = col_indeces)\n",
    "    agg_dFrame = hp.aggregateFromTo(dFrame, from_col=dFrame.columns[0],\n",
    "                               to_col=dFrame.columns[1]).sort_values(by = 'Count', ascending = False)\n",
    "\n",
    "    # Giving unique indeces to each origin and destination\n",
    "    agg_dFrame['from_id'] = pd.factorize(agg_dFrame.iloc[:,0])[0]\n",
    "    agg_dFrame['to_id'] = pd.factorize(agg_dFrame.iloc[:,1])[0]\n",
    "    agg_dFrame['to_id'] = agg_dFrame['to_id'].apply(lambda x: x + 1 + max(agg_dFrame['from_id']))\n",
    "    agg_dFrame.head()\n",
    "\n",
    "    # Because the Sankey package takes data in a weird format for labeling, have to do a few more transforms\n",
    "    agg_dFrame = agg_dFrame.sort_values(by = [\"from_id\", \"to_id\"])\n",
    "    agg_dFrame\n",
    "    labels = np.append(agg_dFrame.iloc[:,0].unique(), agg_dFrame.iloc[:,1].unique())\n",
    "\n",
    "    # Attaching labels to the data in Sankey format\n",
    "    n_blank = agg_dFrame.shape[0] - len(labels)\n",
    "    labels = np.append(labels, [\"\"] * n_blank)\n",
    "    agg_dFrame['Label'] = labels\n",
    "    \n",
    "    return agg_dFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dFrame = hp.sankeyFormat(raw_data,[13,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Source  Target  Value\n",
       "50       0      10    166\n",
       "54       0      11    104\n",
       "53       0      12    101\n",
       "45       0      13     50\n",
       "48       0      14     32\n",
       "..     ...     ...    ...\n",
       "0        9      16      1\n",
       "3        9      17      1\n",
       "8        9      18      1\n",
       "5        9      19      3\n",
       "7        9      20      2\n",
       "\n",
       "[108 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Writing wrapper function to draw Sankey\n",
    "\n",
    "def drawSankey(dFrame):\n",
    "    # Creating a data frame just with nodes for our Sankey plot\n",
    "    # Need ID & Label\n",
    "    from_nodes = dFrame[['from_id', 'From']].drop_duplicates()\n",
    "    from_nodes.columns = ['Node', \"Label\"]\n",
    "\n",
    "    to_nodes = dFrame[['to_id', 'To']].drop_duplicates()\n",
    "    to_nodes.columns = ['Node', 'Label']\n",
    "    nodes_df = from_nodes.append(to_nodes).reset_index(drop = True).sort_values(by = \"Node\")\n",
    "\n",
    "    # # Creating a data frame with just links for Sankey plot\n",
    "    links_df = dFrame[['from_id', 'to_id', 'Count']]\n",
    "    links_df.columns = ['Source', 'Target', 'Value']\n",
    "    links_df = links_df.sort_values(by = ['Source', 'Target'])\n",
    "\n",
    "    # Drawing Sankey\n",
    "    data_trace = dict(\n",
    "        type='sankey',\n",
    "        orientation = \"h\",\n",
    "        valueformat = \".0f\",\n",
    "\n",
    "        # Creating node structure\n",
    "        node = dict(\n",
    "          pad = 10,\n",
    "          thickness = 30,\n",
    "          line = dict(\n",
    "            color = \"black\",\n",
    "            width = 0\n",
    "          ),\n",
    "          label =  nodes_df['Label'].dropna(axis=0, how='any'),\n",
    "\n",
    "        ),\n",
    "\n",
    "        # Creating link structure\n",
    "        link = dict(\n",
    "          source = links_df['Source'].dropna(axis=0, how='any'),\n",
    "          target = links_df['Target'].dropna(axis=0, how='any'),\n",
    "          value = links_df['Value'].dropna(axis=0, how='any')\n",
    "      )\n",
    "    )\n",
    "\n",
    "    layout =  dict(\n",
    "        title = title,\n",
    "        height = 850,\n",
    "        width = 1000,\n",
    "        font = dict(\n",
    "          size = 15\n",
    "        ),    \n",
    "    )\n",
    "\n",
    "    fig = dict(data=[data_trace], layout=layout)\n",
    "\n",
    "    return fig\n",
    "\n",
    "iplot(fig, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'div': {'BrBG': ['rgb(84,48,5)',\n",
       "   'rgb(140,81,10)',\n",
       "   'rgb(191,129,45)',\n",
       "   'rgb(223,194,125)',\n",
       "   'rgb(246,232,195)',\n",
       "   'rgb(245,245,245)',\n",
       "   'rgb(199,234,229)',\n",
       "   'rgb(128,205,193)',\n",
       "   'rgb(53,151,143)',\n",
       "   'rgb(1,102,94)',\n",
       "   'rgb(0,60,48)'],\n",
       "  'PRGn': ['rgb(64,0,75)',\n",
       "   'rgb(118,42,131)',\n",
       "   'rgb(153,112,171)',\n",
       "   'rgb(194,165,207)',\n",
       "   'rgb(231,212,232)',\n",
       "   'rgb(247,247,247)',\n",
       "   'rgb(217,240,211)',\n",
       "   'rgb(166,219,160)',\n",
       "   'rgb(90,174,97)',\n",
       "   'rgb(27,120,55)',\n",
       "   'rgb(0,68,27)'],\n",
       "  'PiYG': ['rgb(142,1,82)',\n",
       "   'rgb(197,27,125)',\n",
       "   'rgb(222,119,174)',\n",
       "   'rgb(241,182,218)',\n",
       "   'rgb(253,224,239)',\n",
       "   'rgb(247,247,247)',\n",
       "   'rgb(230,245,208)',\n",
       "   'rgb(184,225,134)',\n",
       "   'rgb(127,188,65)',\n",
       "   'rgb(77,146,33)',\n",
       "   'rgb(39,100,25)'],\n",
       "  'PuOr': ['rgb(127,59,8)',\n",
       "   'rgb(179,88,6)',\n",
       "   'rgb(224,130,20)',\n",
       "   'rgb(253,184,99)',\n",
       "   'rgb(254,224,182)',\n",
       "   'rgb(247,247,247)',\n",
       "   'rgb(216,218,235)',\n",
       "   'rgb(178,171,210)',\n",
       "   'rgb(128,115,172)',\n",
       "   'rgb(84,39,136)',\n",
       "   'rgb(45,0,75)'],\n",
       "  'RdBu': ['rgb(103,0,31)',\n",
       "   'rgb(178,24,43)',\n",
       "   'rgb(214,96,77)',\n",
       "   'rgb(244,165,130)',\n",
       "   'rgb(253,219,199)',\n",
       "   'rgb(247,247,247)',\n",
       "   'rgb(209,229,240)',\n",
       "   'rgb(146,197,222)',\n",
       "   'rgb(67,147,195)',\n",
       "   'rgb(33,102,172)',\n",
       "   'rgb(5,48,97)'],\n",
       "  'RdGy': ['rgb(103,0,31)',\n",
       "   'rgb(178,24,43)',\n",
       "   'rgb(214,96,77)',\n",
       "   'rgb(244,165,130)',\n",
       "   'rgb(253,219,199)',\n",
       "   'rgb(255,255,255)',\n",
       "   'rgb(224,224,224)',\n",
       "   'rgb(186,186,186)',\n",
       "   'rgb(135,135,135)',\n",
       "   'rgb(77,77,77)',\n",
       "   'rgb(26,26,26)'],\n",
       "  'RdYlBu': ['rgb(165,0,38)',\n",
       "   'rgb(215,48,39)',\n",
       "   'rgb(244,109,67)',\n",
       "   'rgb(253,174,97)',\n",
       "   'rgb(254,224,144)',\n",
       "   'rgb(255,255,191)',\n",
       "   'rgb(224,243,248)',\n",
       "   'rgb(171,217,233)',\n",
       "   'rgb(116,173,209)',\n",
       "   'rgb(69,117,180)',\n",
       "   'rgb(49,54,149)'],\n",
       "  'RdYlGn': ['rgb(165,0,38)',\n",
       "   'rgb(215,48,39)',\n",
       "   'rgb(244,109,67)',\n",
       "   'rgb(253,174,97)',\n",
       "   'rgb(254,224,139)',\n",
       "   'rgb(255,255,191)',\n",
       "   'rgb(217,239,139)',\n",
       "   'rgb(166,217,106)',\n",
       "   'rgb(102,189,99)',\n",
       "   'rgb(26,152,80)',\n",
       "   'rgb(0,104,55)'],\n",
       "  'Spectral': ['rgb(158,1,66)',\n",
       "   'rgb(213,62,79)',\n",
       "   'rgb(244,109,67)',\n",
       "   'rgb(253,174,97)',\n",
       "   'rgb(254,224,139)',\n",
       "   'rgb(255,255,191)',\n",
       "   'rgb(230,245,152)',\n",
       "   'rgb(171,221,164)',\n",
       "   'rgb(102,194,165)',\n",
       "   'rgb(50,136,189)',\n",
       "   'rgb(94,79,162)']},\n",
       " 'qual': {'Paired': ['rgb(166,206,227)',\n",
       "   'rgb(31,120,180)',\n",
       "   'rgb(178,223,138)',\n",
       "   'rgb(51,160,44)',\n",
       "   'rgb(251,154,153)',\n",
       "   'rgb(227,26,28)',\n",
       "   'rgb(253,191,111)',\n",
       "   'rgb(255,127,0)',\n",
       "   'rgb(202,178,214)',\n",
       "   'rgb(106,61,154)',\n",
       "   'rgb(255,255,153)'],\n",
       "  'Set3': ['rgb(141,211,199)',\n",
       "   'rgb(255,255,179)',\n",
       "   'rgb(190,186,218)',\n",
       "   'rgb(251,128,114)',\n",
       "   'rgb(128,177,211)',\n",
       "   'rgb(253,180,98)',\n",
       "   'rgb(179,222,105)',\n",
       "   'rgb(252,205,229)',\n",
       "   'rgb(217,217,217)',\n",
       "   'rgb(188,128,189)',\n",
       "   'rgb(204,235,197)']},\n",
       " 'seq': {}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import colorlover as cl\n",
    "cl.scales['11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Two columns that'll be used\n",
    "\n",
    "col_indeces = [4, 16]\n",
    "raw_data.columns[col_indeces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstNormal(dFrame, col_indeces = []):\n",
    "    '''\n",
    "    Function that takes in a dataframe and returns a the same information as a dataframe in \n",
    "    first normal form (each cell contains only one piece of data). Parameter col_indeces is \n",
    "    a list of column indeces to include when making pairs. \n",
    "    If not included, all possible combinations are too large.\n",
    "    '''\n",
    "    \n",
    "    nrows = dFrame.shape[0]\n",
    "    \n",
    "    if col_indeces == []:\n",
    "        cols = dFrame.columns\n",
    "    else:\n",
    "        cols = dFrame.columns[col_indeces]\n",
    "        \n",
    "    returnDF = pd.DataFrame(columns = cols)\n",
    "        \n",
    "    \n",
    "    for i in range(nrows):\n",
    "        row_lst = []\n",
    "        \n",
    "        for c in cols:\n",
    "\n",
    "            cell_list = [x.strip(\"[]\\\"' \") for x in dFrame[c].loc[i].replace('\", ', \"', \").split(\"', \")]\n",
    "            row_lst.append(cell_list)\n",
    "            \n",
    "        NF1_rows = pd.DataFrame.from_records(list(itertools.product(*row_lst)), columns=cols)\n",
    "        \n",
    "        returnDF = returnDF.append(NF1_rows)\n",
    "    \n",
    "    return returnDF.reset_index(drop = True)\n",
    "\n",
    "def oneHot(dFrame):\n",
    "    '''\n",
    "    Function that takes in a dataframe and returns the information where all categories \n",
    "    are one-hot encoded.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using firstNormal function to get From -> To data pairs and renaming columns\n",
    "\n",
    "from_to = firstNormal(raw_data, col_indeces=[16,4])\n",
    "from_to.columns = ['From', 'To']\n",
    "from_to.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregateFromTo(dFrame, from_col = 'From', to_col = 'To'):\n",
    "    '''\n",
    "    Function that takes in a dataframe of from -> to preferences and returns aggregated counts \n",
    "    of all from -> to pairs.\n",
    "    '''\n",
    "    \n",
    "    # First group by and use size for aggregations\n",
    "    from_to_agg = dFrame.groupby([from_col, to_col]).size().reset_index()\n",
    "    from_to_agg.columns = [from_col, to_col, 'Count']\n",
    "    \n",
    "    # Remove any rows where From and To are the same\n",
    "    from_to_agg = from_to_agg[from_to_agg[from_col] != from_to_agg[to_col]]\n",
    "    \n",
    "    return from_to_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the counts of from -> to pairs\n",
    "agg_from_to = aggregateFromTo(from_to).sort_values(by = 'Count', ascending = False)\n",
    "agg_from_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Weird entry going on in the data, just will remove it for now\n",
    "from_to_id = agg_from_to[(agg_from_to['From'] != 'mck') & (agg_from_to['From'] != '2434 south braddock ave')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving unique indeces to each origin and destination\n",
    "from_to_id['from_id'] = pd.factorize(from_to_id.From)[0]\n",
    "from_to_id['to_id'] = pd.factorize(from_to_id.To)[0]\n",
    "from_to_id['to_id'] = from_to_id['to_id'].apply(lambda x: x + 1 + max(from_to_id['from_id']))\n",
    "from_to_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the Sankey package takes data in a weird format for labeling, have to do a few more transforms\n",
    "from_to_id = from_to_id.sort_values(by = [\"from_id\", \"to_id\"])\n",
    "labels = np.append(from_to_id.From.unique(), from_to_id.To.unique())\n",
    "\n",
    "n_blank = from_to_id.shape[0] - len(labels)\n",
    "print(n_blank)\n",
    "labels = np.append(labels, [\"\"] * n_blank)\n",
    "from_to_id['Label'] = labels\n",
    "from_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all from_ids\n",
    "\n",
    "from_to_id.from_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List of all to_ids\n",
    "\n",
    "np.sort(from_to_id.to_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating a data frame just with nodes for our Sankey plot\n",
    "# Need ID & Label\n",
    "from_nodes = from_to_id[['from_id', 'From']].drop_duplicates()\n",
    "from_nodes.columns = ['Node', \"Label\"]\n",
    "\n",
    "to_nodes = from_to_id[['to_id', 'To']].drop_duplicates()\n",
    "to_nodes.columns = ['Node', 'Label']\n",
    "\n",
    "nodes_df = from_nodes.append(to_nodes).reset_index(drop = True).sort_values(by = \"Node\")\n",
    "nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a data frame with just links for Sankey plot\n",
    "links_df = from_to_id[['from_id', 'to_id', 'Count']]\n",
    "links_df.columns = ['Source', 'Target', 'Value']\n",
    "links_df = links_df.sort_values(by = ['Source', 'Target'])\n",
    "links_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_trace = dict(\n",
    "    type='sankey',\n",
    "#     domain = dict(\n",
    "#       x =  [0,1],\n",
    "#       y =  [0,1]\n",
    "#     ),\n",
    "    orientation = \"h\",\n",
    "    valueformat = \".0f\",\n",
    "    node = dict(\n",
    "      pad = 10,\n",
    "      thickness = 30,\n",
    "      line = dict(\n",
    "        color = \"black\",\n",
    "        width = 0\n",
    "      ),\n",
    "      label =  nodes_df['Label'].dropna(axis=0, how='any'),\n",
    "\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = links_df['Source'].dropna(axis=0, how='any'),\n",
    "      target = links_df['Target'].dropna(axis=0, how='any'),\n",
    "      value = links_df['Value'].dropna(axis=0, how='any')\n",
    "  )\n",
    ")\n",
    "\n",
    "\n",
    "fig = dict(data=[data_trace])\n",
    "iplot(fig, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_to_id[(from_to_id.From == \"Penn Hills Township\") & (from_to_id.To == \"Edgewood Borough\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sankey: Barriers to Transit -> Current Modes of Transit\n",
    "### 61C Corridor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Mon Valley via Homestead (61C Corridor)'\n",
    "12 - Other Transport Used \t12 - Why Other Transport Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_indeces = [13, 12]\n",
    "\n",
    "cor_61c = raw_data[raw_data['6 - Corridor preference']==\"['Mon Valley via Homestead (61C Corridor)']\"]\n",
    "firstNormal(cor_61c, col_indeces=col_indeces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_indeces = [13, 12]\n",
    "print(raw_data.columns[col_indeces])\n",
    "\n",
    "cor_61c = raw_data[raw_data['6 - Corridor preference']==\"['Mon Valley via Homestead (61C Corridor)']\"]\n",
    "\n",
    "# barriers_transit = firstNormal(cor_61c, col_indeces=col_indeces)\n",
    "# barriers_transit.columns = [\"Why\", \"Other_transit\"]\n",
    "# barriers_transit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the counts of from -> to pairs\n",
    "agg_barr_trans = aggregateFromTo(barriers_transit, from_col=\"Why\", \n",
    "                                 to_col=\"Other_transit\").sort_values(by = 'Count', ascending = False)\n",
    "agg_barr_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving unique indeces to each origin and destination\n",
    "from_to_id['from_id'] = pd.factorize(from_to_id.From)[0]\n",
    "from_to_id['to_id'] = pd.factorize(from_to_id.To)[0]\n",
    "from_to_id['to_id'] = from_to_id['to_id'].apply(lambda x: x + 1 + max(from_to_id['from_id']))\n",
    "from_to_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
